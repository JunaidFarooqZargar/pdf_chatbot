{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "#URL of the PDF file\n",
    "# url = 'https://ieeexplore.ieee.org/document/9574048'\n",
    "\n",
    "#Download the papar here.\n",
    "pdf = 'deep_learning_paper.pdf'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [],
   "source": [
    "papers = []\n",
    "loader = PyPDFLoader(pdf)\n",
    "document = loader.load()\n",
    "papers.append(document)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunked_papers length is: 63\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "chunked_papers = []\n",
    "for paper in papers:\n",
    "    texts = text_splitter.split_documents(paper)\n",
    "    chunked_papers.append(texts)\n",
    "    print(f\"chunked_papers length is: {len(texts)}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "data": {
      "text/plain": "[Document(page_content='Deep Learning for Self-tuning of Control systems\\nJunaid Farooq\\nDepartment of Electrical Engineering\\nNational Institute of Technology Srinagar\\nSrinagar, India\\njunaid phd017@nitsri.ac.inMohammad Abid Bazaz\\nDepartment of Electrical Engineering\\nNational Institute of Technology Srinagar\\nSrinagar, India\\nabid@nitsri.ac.in\\nAbstract —This paper proposes an innovative two-dimensional\\nmulti-layered deep neural network (DNN) to achieve adaptive,', metadata={'source': 'deep_learning_paper.pdf', 'page': 0}),\n Document(page_content='physics-informed, model-free and data-based control of stochas-\\ntic, sensitive and highly nonlinear systems. The algorithm design\\nexploits the DNN features of adaptive learning, inference of latent\\nvariables and time-series prediction to update the controller\\nparameters on-the-run in real-time while compensating for the\\nloop delays at the same time in addition to the system processing\\ntime. The proposed deep learning based self-tuning algorithm', metadata={'source': 'deep_learning_paper.pdf', 'page': 0}),\n Document(page_content='(DLSTA) is generic and can be used for online self-tuning of\\ncontroller parameters in general. For the purpose of this paper,\\nit is applied on the speed control of the brushless DC (BLDC)\\nmotor in an electric vehicle (EV) using PID controller on the\\nfront-end. The simulation results demonstrate the superiority of\\nthe proposed scheme over other conventional tuning methods.\\nIndex Terms —Deep Learning, Recurrent Neural Network,\\nIntelligent Control, Adaptive Control, Predictive Control', metadata={'source': 'deep_learning_paper.pdf', 'page': 0}),\n Document(page_content='I. I NTRODUCTION\\nThis paper proposes a state-of-the-art deep learning tech-\\nnique to address four major challenges in design and modeling\\nof control systems viz: a) loop delays, b) nonlinearity, c)\\nstochasticity, and d) sensitivity.\\nLoop delays arising from control interfaces and system\\nprocessing are inevitable in numerous engineering problems\\n[1]. Such delays are also caused due to model order reduction\\nand other such techniques used in modeling of complex', metadata={'source': 'deep_learning_paper.pdf', 'page': 0}),\n Document(page_content='physical phenomena. The introduction of loop delays into\\nthe system limits its performance as measurement channel\\ndelays supply the controller with outdated information and\\nactuation channel delays defer the control actions. Such delay\\nelements also complicate the controller design process as\\nthey belong to the inﬁnite dimensional functional differential\\nequations (FDEs), instead of the ﬁnite dimensional ordinary\\ndifferential equations (ODEs), which limits the application', metadata={'source': 'deep_learning_paper.pdf', 'page': 0}),\n Document(page_content='of many traditional methods [2]. Many methods have been\\nproposed in the literature to solve the stabilization problems\\narising from loop delays like approximation of delays [3],\\ncompensation of delays [4], interface control [5] etc. However,\\nthe problem of loop delays still remains a challenge.\\nTraditional control systems are based on linear dynamic\\nmodels. However, for highly nonlinear dynamic systems, linear\\ncontrollers often fail to provide adequate control performance.', metadata={'source': 'deep_learning_paper.pdf', 'page': 0}),\n Document(page_content='With increase in nonlinearity, control of the system becomes\\nThis work was funded by Ministry of Education, Government of India.highly complex and challenging [6]. Traditionally, lineariza-\\ntion has been used as the main approach to deal with non-\\nlinear systems [7]. Model order reduction techniques [8] have\\nemerged as an alternate method of reducing the computational\\nburden associated with modeling, control and simulation of\\nnonlinear systems [9].', metadata={'source': 'deep_learning_paper.pdf', 'page': 0}),\n Document(page_content='Many systems are stochastic in nature with inherent para-\\nmetric uncertainties. Such uncertainties introduce inaccuracies\\nin modeling and design of controllers producing errors in\\nthe system output [10]. These errors become signiﬁcantly\\nchallenging in case of highly sensitive systems like control of\\nlow-inertia power systems, mircrogrids with high renewable\\nenergy penetration, hypersonic ﬂight vehicle control, control\\nof power electronic converters, automatic process control etc.', metadata={'source': 'deep_learning_paper.pdf', 'page': 0}),\n Document(page_content='Many parameters like position, orientation, pressure, tempera-\\nture, solar irradiance for solar power parks etc vary with time\\nwhile as many others like power system load, missile-target\\nrelative position, wind speed for wind farms, obstacles for\\nautonomous vehicles etc are stochastic in nature and expose\\nthe system to unaccounted disturbances causing instability\\n[11]. Many methods have been discussed in the literature\\nto synergize probabilistic systems with deterministic methods', metadata={'source': 'deep_learning_paper.pdf', 'page': 0}),\n Document(page_content='[12]. Optimal stochastic controllers have been proposed to\\nminimize Kullback-Leibler divergence of closed-loop systems\\nusing probabilistic descriptions [13].\\nDeep neural network (DNN) based artiﬁcial intelligence\\ntechniques have proven as effective methods of dealing with\\ncomplexity and diversity of modern software and hardware\\n[14]. The current work uses an innovative two-dimensional\\nmulti-layer DNN to address the problems of loop delays,', metadata={'source': 'deep_learning_paper.pdf', 'page': 0}),\n Document(page_content='nonlinearity, stochasticity and sensitivity present in control\\nsystems. The proposed DNN architecture exploits the pre-\\ndiction feature of recurrent neural networks (RNN) to deal\\nwith loop delays and stochastic nature of the system by\\nusing gated-tanh ReLU units (GTRU) in the time dimension.\\nTime-ahead values of uncertain parameters are predicted to\\ncompensate for loop delays and system processing time. The\\nspace dimension of the proposed learning system is inspired', metadata={'source': 'deep_learning_paper.pdf', 'page': 0}),\n Document(page_content='by feedforward artiﬁcial neural network (ANN) architecture\\nhaving the properties of estimation, inference of latent vari-\\nables and adaptive learning which is deployed to make the\\ncontrol system adaptive and robust to deal with nonlinearity\\nand sensitivity. The training data for the space dimension of\\nthe learning system is generated in the ofﬂine mode by using', metadata={'source': 'deep_learning_paper.pdf', 'page': 0}),\n Document(page_content='Fig. 1. System Model\\ngenetic algorithm (GA). The choice of GA is inspired from\\nthe fact that most of the training data would be concentrated\\naround the optimal values. The input-output data generated\\nfrom all the iterations of GA optimization are stored for\\ntraining the DNN to estimate the system dynamics. The well\\ntrained, model-free and physics-informed DNN is employed to\\nupdate the controller parameters in real-time on-the-run with\\nzero output error as one input along with stochastic system', metadata={'source': 'deep_learning_paper.pdf', 'page': 1}),\n Document(page_content='parameters as other inputs.\\nRemark 1: The DNN architecture is two-dimensional in\\nthe sense that its RNN part is trained online and hence\\nreferred as the time-dimension as it ensures real-time operation\\nby compensating for the algorithm processing time, and its\\nANN part is trained ofﬂine and hence referred as the space-\\ndimension as it captures that system physics. It is not merely\\na two-stage algorithm in which one stage follows the other.', metadata={'source': 'deep_learning_paper.pdf', 'page': 1}),\n Document(page_content='The two dimensions work simultaneously to ensure real-time\\noperation and self-tuning of the control system.\\nII. S YSTEM MODELING\\nThe proposed technique is generic and can be used for\\nonline self-tuning of controller parameters in general. For the\\npurpose of this paper, it is applied on PID control which is the\\nmost widely used control technique in general. A case of speed\\ncontrol of an electric vehicle (EV) with brushless DC (BLDC)\\nmotor is considered. BLDC motors are ideal for EVs due to', metadata={'source': 'deep_learning_paper.pdf', 'page': 1}),\n Document(page_content='their high power densities, good speed-torque characteristics,\\nhigh efﬁciency, wide speed ranges, and low maintenance [15].\\nFig. 1 shows the system model where BLDC motor drives\\nthe EV dynamics. The desired speed command (r)is issued by\\nthe driver by pushing the foot pedal. Error signal (e=r\\x00y)\\nis fed to the controller which adjusts the BLDC motor speed\\nso as to reduce the error to zero.\\nThe BLDC motor is governed by the following equations:\\nV=Ri+ (L\\x00M)di\\ndt+E (1)\\nE=Ke!F (2)\\nT=KtiF (3)', metadata={'source': 'deep_learning_paper.pdf', 'page': 1}),\n Document(page_content='whereVis phase voltage, Eis the back-emf and Tis the\\ntorque.KiandKtare constants, !is the angular speed of the\\nmotor andiis the phase current. LandMrepresent the phase\\nFig. 2. Typical plant and controller model\\ninductance and mutual inductance. Frepresents the ﬂux. The\\nsystem modeling was completed according to the details given\\nby [16]–[18] which also show the system nonlinearity.\\nThe desired speed command issued by the driver is a\\nstochastic parameter which depends on multiple factors. An-', metadata={'source': 'deep_learning_paper.pdf', 'page': 1}),\n Document(page_content='other parametric uncertainty is introduced into the system by\\nthe road inclination angle which keeps changing continuously.\\nThese uncertainties require the control system to adjust its\\nparameters adaptively. Further, delays are introduced into the\\nsystem due to the control loop and inherent time-lags of\\nmultiple sensors and other electronic equipment. These delays\\nsupply outdated information to the controller which in turn\\nissues control commands that are actually meant for a previous', metadata={'source': 'deep_learning_paper.pdf', 'page': 1}),\n Document(page_content='time. The system parameters might have changed during this\\ntime period. These issues are addressed in the next section.\\nIII. D EEPLEARNING BASED SELF-TUNING ALGORITHM\\nFig. 2 represents the general structure of plant and controller\\nwhereyis the actual output and ris the desired output. Error\\ndeﬁned ase=r\\x00yis fed to the controller C(s)which\\nproduces a suitable input ufor the plant P(s). PID controllers\\nare described by the following equation:\\nu(t) =Kpe(t) +KiIe(t) +KdDe(t) (4)', metadata={'source': 'deep_learning_paper.pdf', 'page': 1}),\n Document(page_content='whereKpa,KiandKdare controller parameters. The Laplace\\ntransform of (4) is described as:\\nC(s) =Kp+Kis\\x001+Kds (5)\\nIn case the plant is highly non-linear with probabilistic\\ndynamics, it is difﬁcult to ﬁnd optimal values of the controller\\nparameters. Further, ﬁxed ofﬂine tune parameter values may\\nnot be optimal for all scenarios. Therefore, it is necessary\\nthat the controller parameters are tuned in an adaptive and\\nintelligent manner according the ever-changing desired output', metadata={'source': 'deep_learning_paper.pdf', 'page': 1}),\n Document(page_content='signal while anticipating the future behavior of the signal as\\nwell. This section describes the proposed deep learning based\\nself-tuning algorithm (DLSTA) for on-the-run optimization of\\ncontroller parameters as follows.\\nA. Training Data Generation\\nThe process of generating training data is completed using\\ngenetic algorithm. Since this process is completed ofﬂine,\\ntherefore no efforts are made to accomplish it in the shortest\\npossible time. The goal is to generate sufﬁciently large data to', metadata={'source': 'deep_learning_paper.pdf', 'page': 1}),\n Document(page_content='achieve high accuracy levels during the neural network training\\nprocess. Genetic algorithm is implemented for all possible\\nspeed commands in 1-100 kmph range with an increment of 1', metadata={'source': 'deep_learning_paper.pdf', 'page': 1}),\n Document(page_content='kmph; and road inclination angles in -45 to 45 deg range with\\nincrements of 1 deg. The minimization of the error signal is\\ndeclared as the objective function. Thus, the GA is run 9100\\ntimes and values of road inclination angle, foot pedal speed\\ncommand and PID controller parameters generated during\\neach iteration are stored as the training data.\\nB. DNN Architecture\\nThe DNN estimates the EV system dynamics from the train-\\ning data and adaptively optimizes the controller parameters', metadata={'source': 'deep_learning_paper.pdf', 'page': 2}),\n Document(page_content='on-the-run according to the driver’s speed command and road\\ninclination angle to minimize the error. However, it is expected\\nthat the parameter tuning process suffers from critical errors\\narising due to the time-lag between the initial sensing of vari-\\nous parameters and ﬁnal calculation of controller parameters.\\nThe delay is caused due to a)inherent time delay in the\\nphysical sensors installed on the system, b)processing-time of\\nmultiple intelligent electronic systems installed, c)control loop', metadata={'source': 'deep_learning_paper.pdf', 'page': 2}),\n Document(page_content='dynamics and (d)the processing-time of the DNN algorithm. If\\nTdis the total time-lag, then the controller parameters obtained\\nat timetare actually optimized for the system parameters at\\na previous time t\\x00Td. The current values of the parameters\\nmay be different from what they were at time t\\x00Td.\\nTo solve this problem, the DNN architecture proposed in\\nthis paper, as shown in Fig. 3, has two dimensions: space and\\ntime or estimation and prediction. The estimation orspace', metadata={'source': 'deep_learning_paper.pdf', 'page': 2}),\n Document(page_content='dimension estimates the nonlinear dynamics between the con-\\ntroller parameters ( Kp;Ki;Kd), error (e), speed commands\\n(r)and road inclination (\\x1e). It is based on deep feedforward\\nneural network having 3 hidden layers with 600, 30 and 10\\nneurons respectively and assumes the nonlinear dynamics as\\nfollows:\\ne=fNL(r;\\x1e;K p;Ki;Kd) (6)\\nwhereeis the error between desired speed and actual speed;\\nandfNLa highly nonlinear function estimated by the this part', metadata={'source': 'deep_learning_paper.pdf', 'page': 2}),\n Document(page_content='of the network architecture.. From (6), it can be stated that:\\n2\\n4Kp\\nKi\\nKd3\\n5=2\\n4g1;NL(r;\\x1e;e )\\ng2;NL(r;\\x1e;e )\\ng5;NL(r;\\x1e;e )3\\n5=gNL(r;\\x1e;e ) (7)\\nwheregNLis a highly nonlinear vector function. As is shown\\nin Fig. 3, the space dimension is fed with e\\x190and the real-\\ntime predicted \\x1eandras inputs which generates the PID\\ncontroller parameters for the speed command and zero error.\\nThus, the nonlinear estimation function gNLimplemented\\nby the ANN inspired space dimension of the DNN updates', metadata={'source': 'deep_learning_paper.pdf', 'page': 2}),\n Document(page_content='the controller parameters online in an adaptive and intelligent\\nmanner. This dimension is particularized by its own weights\\nand biases which are tuned ofﬂine from the training data using\\nthe backpropagation learning based on Levenberg-Marquardt\\nalgorithm as follows:\\nInput =\\x02e r \\x1e\\x03\\n(8)\\nOutput =\\x02KpKiKd\\x03\\n(9)![l]\\nij(k+ 1) =![l]\\nij(k)\\x00\\x11@J\\n@![l]\\nij(10)\\nv[l]\\ni(k+ 1) =v[l]\\ni(k)\\x00\\x11@J\\n@v[l]\\ni(11)\\nwhere![l]\\nijis the weight between ithneuron in layer landjth', metadata={'source': 'deep_learning_paper.pdf', 'page': 2}),\n Document(page_content='neuron in layer l\\x001andvis the bias for ithneuron of the\\nlthlayer.\\x11is the learning rate and kis the iteration instant.\\nJis the performance index to be minimized deﬁned as:\\nminJ=1\\n2[r(k)\\x00y(k)]2(12)\\nwhereJrepresents the difference between the desired and\\nactual values of the plant output (EV speed in this paper), not\\nto be confused with the prediction error which is the difference\\nbetween the actual and predicted outputs of the RNN.\\nThe second dimension of the DNN architecture is the', metadata={'source': 'deep_learning_paper.pdf', 'page': 2}),\n Document(page_content='prediction ortime dimension that predicts speed commands\\nand road inclination angle, the most critical stochastic system\\nparameters, to compensate for the total system delay. This\\ntask is undertaken by the RNN based part of the architecture\\nwhich extracts the pattern in the driver’s behavior and road\\ninclinations and accordingly predicts these two parameters\\nwith a short prediction horizon that is equal to the total system\\ntime-lag. This part of the architecture consists of multiple', metadata={'source': 'deep_learning_paper.pdf', 'page': 2}),\n Document(page_content='RNN layers inspired by the LSTM network [19] which is\\nknown for accurate time-series prediction with online learning.\\nA modiﬁed version of LSTM network augmented by peephole\\nconnections has been used which generates highly stable\\nsequences of nonlinear, precisely timed spikes without loss of\\nperformance [20]. Each network has three sublayers deﬁned\\nby:\\nft=\\x1b(Wf\\x01[ct\\x001;ht\\x001;\\x1e] +bf) : forget gate (13)\\nit=\\x1b(Wi\\x01[ct\\x001;ht\\x001;\\x1e] +bi) : input gate (14)\\not=\\x1b(Wo\\x01[ct\\x001;ht\\x001;\\x1e] +bo) : output gate (15)', metadata={'source': 'deep_learning_paper.pdf', 'page': 2}),\n Document(page_content='wherectrepresents cell state at time tandhtis the prediction\\nat timet. The outputs are deﬁned as:\\nct=ft\\x03ct\\x001+it\\x03(tanh(Wc\\x01[ht\\x001;xt] +bc)) (16)\\nht=ot\\x03tanh(ct) (17)\\nThe input gate in (14) decides the new values that are to be\\nstored in the cell state by implementing a sigmoid function. In\\n(16) the cell state is updated by initially multiplying the old\\nstate by forget gate which lets only the required information\\nto pass through and the rest is forgotten. Then the information', metadata={'source': 'deep_learning_paper.pdf', 'page': 2}),\n Document(page_content='released by the input gate is added to the state after multiplying\\nit by a tanh layer. The new cell state is put through a tanh\\nlayer in (17) to push the values within [-1,1] interval and\\nthen multiplied by the output gate information to generate the\\nprediction.\\nA 20 layer network is considered which takes as input the\\nsequence of last 20 values of \\x1eand outputs a predicted value\\nof\\x1et+Pcompensating for Pinstants when run Ptimes while\\nupdating the network states and incorporating the predicted', metadata={'source': 'deep_learning_paper.pdf', 'page': 2}),\n Document(page_content='Fig. 3. DNN architecture and PID control scheme\\nvalue in each iteration. Online backpropagation through time\\n(BPTT) algorithm [21] is implemented to update network\\nstates and avoid the problem of vanishing gradients as well.\\nTo predict the future behavior, the ﬁnal output of the RNN is\\nfed to full connected dense regression layer deﬁned as:\\n[\\x1et+1;rt+1] =!denseht+bdense (18)\\nwherewdense andbdense are the weights and bias terms in the\\ndense regression layer. Algorithm 1 shows the process of data', metadata={'source': 'deep_learning_paper.pdf', 'page': 3}),\n Document(page_content='generation and training of the space dimension of the DNN.\\nAlgorithm 2 shows the process of time-series prediction by\\nRNN based time dimension and estimation of optimal PID\\nparameters by space dimension of the DNN.\\nAlgorithm 1 Data generation and training\\nstart\\n1:for\\x1e=\\x0045° to45°do\\n2: forr= 1 kmph to 100kmph do\\n3: Randomly initialize\\x02KpKiKd\\x03\\nwithin pre-\\nselected bounds.\\n4: Run GA to minimize the eand store values of eand\\x02KpKiKd\\x03\\ngenerated within each iteration of\\nGA as the training data.', metadata={'source': 'deep_learning_paper.pdf', 'page': 3}),\n Document(page_content='5: end for\\n6:end for Return:\\x02KpKiKd\\x03\\n,\\x02e\\x03\\nand\\x02\\x1e\\x03\\n7:Randomly initialize all ![l]\\nijandv[l]\\nifor all layers of Space\\ndimension using Nguyen-Widrow method.\\n8:Train the space dimension of DNN and update the values\\nof![l]\\nijandv[l]\\niby using backpropagation learning method\\nbased on Levenberg-Marquardt algorithm.\\nendAlgorithm 2 DLSTA\\nInput: Real-time\\x02\\x1et\\x00R+1\\x1et\\x00R+2::: \\x1e t\\x03\\nand\\x02rt\\x00R+1rt\\x00R+2::: r t\\x03\\nOutput: Optimal values of\\x02KpKiKd\\x03\\n.\\n1:fori= 1 :Pdo\\n2: Train the RNN based time dimension of DNN from', metadata={'source': 'deep_learning_paper.pdf', 'page': 3}),\n Document(page_content='input values by using backpropagation through time\\n(BPTT) algorithm.\\n3: Predict [\\x1et+1;et+1] =!denseht+bdense\\n4: Update\\x1ek!\\x1ek+1andrk!rk+1fork=t\\x00R;t\\x00\\nR+ 1;:::;t\\n5: Update the network parameters.\\n6:end for Return\\x1et+Pandrt+P\\n7:For ANN based space dimension, Set Input-1 = \\x1et+P,\\nInput-2 =rt+Pand Input-3 = e= 0:00001\\n8:Run the neural network trained in Algorithm 1 to ob-\\ntain optimal values of PID parameters for e\\x190and\\n[\\x1et+P;rt+P]\\nIV. S IMULATION AND RESULTS', metadata={'source': 'deep_learning_paper.pdf', 'page': 3}),\n Document(page_content='To simulate the effect of real-time system processing time-\\nlag and study the effect of compensation of the same by\\nprediction, a parallel dual-core simulation is performed. Core-\\n1 of the processor simulates the EV dynamics including BLDC\\nmotor while as Core-2 hosts the DLSTA and exchanges the\\ninput and output data with Core-1. The prediction horizon in\\nCore-2 is equal to the processing time of simulation in Core-1.\\nThe data generated using GA is used for training which took', metadata={'source': 'deep_learning_paper.pdf', 'page': 3}),\n Document(page_content='a large amount of time to complete. However, it is a one-time\\nprocess that is completed ofﬂine. The controller parameters\\nare updated after every 0.2 s. The computation time of online\\nBPPT algorithm varies according to the varying prediction', metadata={'source': 'deep_learning_paper.pdf', 'page': 3}),\n Document(page_content='0 10 20 30 40 50\\nTime (seconds)-20020406080100Speed [kmph]Desired\\nDLSTA\\nZN\\nPSOFig. 4. Desired and actual speeds of EV\\n0 10 20 30 40 50\\nTime (seconds)-30-20-10010\\nFig. 5. Road inclination angle\\nhorizon which depends on the processing time of Core-1\\nthat is affected by various factors like system nonlinearity\\nand stiffness. However, the computation time remained well\\nwithin the required bounds when the simulation was run\\non Intel Xeon 3.5 GHz processor with 64 GB RAM. In', metadata={'source': 'deep_learning_paper.pdf', 'page': 4}),\n Document(page_content='real-life implementation, the Simulation on Core-1 would be\\nreplaced with the physical system including the controller\\nwhich would reduce the prediction time horizon to mere\\ncontroller processing time.\\nDuring the simulation experiment, the EV is subjected to\\nfast changing foot pedal speed commands as shown in Fig.\\n4. The speeds below zero represent reverse movement of the\\nvehicle on the road that is going downhill as shown in Fig.\\n5. The driver brieﬂy issues a speed-up command while going', metadata={'source': 'deep_learning_paper.pdf', 'page': 4}),\n Document(page_content='downhill and then quickly reduces the speed. Thus, the EV is\\nsubjected to extreme input commands from the driver under\\nstressing road terrain conditions.\\nNote: These fast-changing road inclinations and unusual\\ndriving speed commands are unlikely to occur in real-life\\nconditions. In real-life situations, the road inclinations are\\nexpected to be much smoother and the driver is unlikely\\nto issue commands to increase speed while going downhill.\\n0 10 20 30 40 5034Kp\\n0 10 20 30 40 500.20.250.3Ki', metadata={'source': 'deep_learning_paper.pdf', 'page': 4}),\n Document(page_content='0 10 20 30 40 50\\nTime (s)0.050.06KdFig. 6. Adaptively changing PID parameters\\nHowever, the purpose here is to test the efﬁciency of the system\\nfor the worst-case scenario, even if it is unlikely to occur.\\nFurther, the algorithm is required to predict with prediction\\nhorizon equal to the the system processing time which is small\\nenough to be affected by the long-term stochasticity of road\\ninclinations or driver speed commands.\\nThe comparison of DLSTA with Ziegler-Nicholas (ZN) and', metadata={'source': 'deep_learning_paper.pdf', 'page': 4}),\n Document(page_content='particle swarm optimization (PSO) methods as described in\\n[22] is shown in Fig. 4. The performance of DLSTA in terms\\nof conformity of actual speed with desired speed is superior\\nthan the other two methods. The ZN and PSO tuning method\\nfail to shown desired performance under the conditions where\\nthere is a swift change of speed command from increasing\\nto decreasing or vice versa. Fig. 6 shows the adaptively\\nchanging PID controller parameters which are continuously', metadata={'source': 'deep_learning_paper.pdf', 'page': 4}),\n Document(page_content='updated according the changing foot pedal command and\\nroad conditions. These results show that there is no loss of\\nperformance even for quick maneuvering of EV speed when\\nDLSTA is used for self-tuning of the controller parameters.\\nPSO and ZN methods show higher sensitivity to parameter\\nuncertainties like fast changing speed command and road\\ninclination.\\nRemark 2: Why is GA used for training data generation?\\nThe purpose is to generate sufﬁcient input-output data for', metadata={'source': 'deep_learning_paper.pdf', 'page': 4}),\n Document(page_content='varying road inclination, speed command and controller pa-\\nrameters. This could be achieved by any technique that uses\\na large number of possible combinations of PID controller\\nparameters for each case of the 9100 possible combinations\\nof road inclination and speed command. If ncombinations of\\nPID controller parameters are used, then the total number of\\ndata points generated would be n\\x029100 . Random values of\\nPID controller parameters could also be used for the purpose', metadata={'source': 'deep_learning_paper.pdf', 'page': 4}),\n Document(page_content='of data generation. However, there is a possibility that none', metadata={'source': 'deep_learning_paper.pdf', 'page': 4}),\n Document(page_content='or very few of those combinations meets the desired condition\\nof error minimization. In that case, the neural network would\\nnot be able to capture the system dynamics properly as the\\nerroreis used as an input to the network with a ﬁxed value\\nclose to zero. Therefore, GA was used as the data generation\\nalgorithm because it is an optimization technique in which the\\ndifferent values of the to-be-optimized parameters are used\\nwhile continuously progressing towards the ﬁnally optimized', metadata={'source': 'deep_learning_paper.pdf', 'page': 5}),\n Document(page_content='values due to its evolutionary nature. Thus, for each case of\\n9100 combinations of road inclination and speed command, it\\nuses a number of combinations of PID controller parameters\\nwhile not only ensuring that the desired or optimized values\\nare included but also concentrating a large number of the\\ncontroller parameters around the optimized values. Although\\nboth the optimal and non-optimal values are supposed to be\\npart of the training data, it desirable that a large part of the', metadata={'source': 'deep_learning_paper.pdf', 'page': 5}),\n Document(page_content='training data is concentrated around the optimal values. This\\nis an important advantage for training the neural network to\\ncapture the system dynamics for the conditions that are most\\nlikely to occur during practical implementation as the job of\\nthe DNN is to generate controller parameters for nearly zero\\nerrore, and thus avoid unnecessarily training the network for\\nvalues that would never be required in practice.\\nV. C ONCLUSION\\nIn this paper, a novel technique is used for physics-', metadata={'source': 'deep_learning_paper.pdf', 'page': 5}),\n Document(page_content='informed, model-free and adaptive predictive control of elec-\\ntric vehicle’s (EV) brushless dc motor. This technique uses a\\ndeep learning based self-tuning algorithm (DLSTA) where a\\nPID controller is used on the front-end and a two-dimensional\\nmulti-layered deep neural network is deployed on the back-\\nend to achieve self-tuning of the controller parameters. Al-\\nthough, this technique is generic and can be used with any\\nrobust controller on the front-end, PID was chosen due to its', metadata={'source': 'deep_learning_paper.pdf', 'page': 5}),\n Document(page_content='widespread acceptance and proven industrial applications. The\\nDNN has a unique architecture that combines the estimation\\nfeature of artiﬁcial neural networks in its space dimension and\\nthe prediction feature of recurrent neural networks in its time\\ndimension. The proposed control algorithm is intelligent as it\\npredicts the foot pedal behavior of the vehicle driver and road\\ninclination angles to compensate for the system processing\\ntime during which the uncertain parameters may have changed', metadata={'source': 'deep_learning_paper.pdf', 'page': 5}),\n Document(page_content='their values. Further, this control technique is adaptive and\\nrobust as the controller parameters are continuously optimized\\nand updated on-the-run according to the expected trajectories\\nof the uncertain parameters. Dual-core parallel simulations\\nare carried out with EV system dynamics simulated on one\\ncore and DLSTA algorithm implemented on another core of\\nthe processor to simulate the real-time effect of system time-\\nlag and the impact of the control scheme on performance,', metadata={'source': 'deep_learning_paper.pdf', 'page': 5}),\n Document(page_content='stability and accuracy of the EV speed control. The simulation\\nresults demonstrate the superiority of the proposed control\\nscheme over conventional methods in terms of performance\\nand robustness. These results could inﬂuence future works in\\nwhich more parameters like gear changes, obstacle avoidance,\\netc are included. More training data could be generatedthrough multiple parameter simulations on supercomputers or\\nfrom actual EVs to further improve the performance of this', metadata={'source': 'deep_learning_paper.pdf', 'page': 5}),\n Document(page_content='technique and explore practical implementation.\\nREFERENCES\\n[1] L. Mirkin and Qing-Chang Zhong, “2dof controller parametrization\\nfor systems with a single i/o delay,” IEEE Transactions on Automatic\\nControl , vol. 48, no. 11, pp. 1999–2003, 2003.\\n[2] L. Mirkin and Z. J. Palmor, “Control issues in systems with loop delays,”\\ninHandbook of networked and embedded control systems . Springer,\\n2005, pp. 627–648.\\n[3] N. Bekiaris-Liberis and M. Krstic, “Compensation of state-dependent', metadata={'source': 'deep_learning_paper.pdf', 'page': 5}),\n Document(page_content='input delay for nonlinear systems,” IEEE Transactions on Automatic\\nControl , vol. 58, no. 2, pp. 275–289, 2013.\\n[4] M. Krstic, “Input delay compensation for forward complete and strict-\\nfeedforward nonlinear systems,” IEEE Transactions on Automatic Con-\\ntrol, vol. 55, no. 2, pp. 287–303, 2010.\\n[5] E. Guillo-Sansano, A. J. Roscoe, C. E. Jones, and G. M. Burt, “A new\\ncontrol method for the power interface in power hardware-in-the-loop', metadata={'source': 'deep_learning_paper.pdf', 'page': 5}),\n Document(page_content='simulation to compensate for the time delay,” in 2014 49th International\\nUniversities Power Engineering Conference (UPEC) , 2014, pp. 1–5.\\n[6] D. P. Atherton, An introduction to nonlinearity in control systems .\\nBookboon, 2011.\\n[7] D. Cheng, X. Hu, and T. Shen, “Linearization of nonlinear systems,”\\ninAnalysis and Design of Nonlinear Control Systems . Springer, 2010,\\npp. 279–313.\\n[8] M. A. Bazaz, S. Janardhanan et al. , “A review of parametric model order', metadata={'source': 'deep_learning_paper.pdf', 'page': 5}),\n Document(page_content='reduction techniques,” in 2012 IEEE International Conference on Signal\\nProcessing, Computing and Control . IEEE, 2012, pp. 1–6.\\n[9] D. Raﬁq and M. A. Bazaz, “A framework for parametric reduction\\nin large-scale nonlinear dynamical systems,” Nonlinear Dynamics , vol.\\n102, no. 3, pp. 1897–1908, 2020.\\n[10] M. K ´arn`y and T. V . Guy, “Fully probabilistic control design,” Systems\\n& Control Letters , vol. 55, no. 4, pp. 259–265, 2006.', metadata={'source': 'deep_learning_paper.pdf', 'page': 5}),\n Document(page_content='[11] A. Lindquist and G. Picci, “Linear stochastic systems,” Series in\\nContemporary Mathematics , vol. 1, 2015.\\n[12] G. C. Calaﬁore, F. Dabbene, and R. Tempo, “Research on probabilistic\\nmethods for control system design,” Automatica , vol. 47, no. 7, pp.\\n1279–1293, 2011.\\n[13] R. Herzallah and M. K ´arn`y, “Fully probabilistic control design in an\\nadaptive critic framework,” Neural networks , vol. 24, no. 10, pp. 1128–\\n1135, 2011.', metadata={'source': 'deep_learning_paper.pdf', 'page': 5}),\n Document(page_content='[14] A. Shrestha and A. Mahmood, “Review of deep learning algorithms and\\narchitectures,” IEEE Access , vol. 7, pp. 53 040–53 065, 2019.\\n[15] X. Nian, F. Peng, and H. Zhang, “Regenerative braking system of electric\\nvehicle driven by brushless dc motor,” IEEE Transactions on Industrial\\nElectronics , vol. 61, no. 10, pp. 5798–5808, 2014.\\n[16] H.-x. Wu, S.-k. Cheng, and S.-m. Cui, “A controller of brushless dc\\nmotor for electric vehicle,” IEEE Transactions on magnetics , vol. 41,', metadata={'source': 'deep_learning_paper.pdf', 'page': 5}),\n Document(page_content='no. 1, pp. 509–513, 2005.\\n[17] U. Vinatha, S. Pola, and K. Vittal, “Simulation of four quadrant operation\\n& speed control of bldc motor on matlab/simulink,” in TENCON 2008-\\n2008 IEEE Region 10 Conference . IEEE, 2008, pp. 1–6.\\n[18] MathWorks Student Competitions Team, “Electric vehicle pow-\\nered by bldc motor,” https://github.com/mathworks/electric-all-terrain-\\nvehicle/releases/tag/v1.0.1.\\n[19] J. Schmidhuber and S. Hochreiter, “Long short-term memory,” Neural', metadata={'source': 'deep_learning_paper.pdf', 'page': 5}),\n Document(page_content='Comput , vol. 9, no. 8, pp. 1735–1780, 1997.\\n[20] F. A. Gers and J. Schmidhuber, “Recurrent nets that time and count,”\\ninProceedings of the IEEE-INNS-ENNS International Joint Conference\\non Neural Networks. IJCNN 2000. Neural Computing: New Challenges\\nand Perspectives for the New Millennium , vol. 3, 2000, pp. 189–194\\nvol.3.\\n[21] F. A. Gers, J. Schmidhuber, and F. Cummins, “Learning to forget:\\nContinual prediction with lstm,” Neural computation , vol. 12, no. 10,\\npp. 2451–2471, 2000.', metadata={'source': 'deep_learning_paper.pdf', 'page': 5}),\n Document(page_content='[22] M. I. Solihin, L. F. Tack, and M. L. Kean, “Tuning of pid controller\\nusing particle swarm optimization (pso),” in Proceeding of the Interna-\\ntional Conference on Advanced Science, Engineering and Information\\nTechnology , vol. 1, 2011, pp. 458–461.', metadata={'source': 'deep_learning_paper.pdf', 'page': 5})]"
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma, Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from tqdm.autonotebook import tqdm\n",
    "import pinecone\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "# Get these API\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')\n",
    "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY')\n",
    "PINECONE_API_ENV = os.environ.get('PINECONE_API_ENV')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "pinecone.init(api_key=PINECONE_API_KEY, environment=PINECONE_API_ENV)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "data": {
      "text/plain": "<function pinecone.manage.list_indexes()>"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pinecone.create_index(\"quickstart\", dimension=8, metric=\"euclidean\", pod_type=\"p1\")\n",
    "pinecone.list_indexes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,\n",
    "    environment=PINECONE_API_ENV\n",
    ")\n",
    "index_name = \"your_index_name\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "data": {
      "text/plain": "[[Document(page_content='Deep Learning for Self-tuning of Control systems\\nJunaid Farooq\\nDepartment of Electrical Engineering\\nNational Institute of Technology Srinagar\\nSrinagar, India\\njunaid phd017@nitsri.ac.inMohammad Abid Bazaz\\nDepartment of Electrical Engineering\\nNational Institute of Technology Srinagar\\nSrinagar, India\\nabid@nitsri.ac.in\\nAbstract —This paper proposes an innovative two-dimensional\\nmulti-layered deep neural network (DNN) to achieve adaptive,', metadata={'source': 'deep_learning_paper.pdf', 'page': 0}),\n  Document(page_content='physics-informed, model-free and data-based control of stochas-\\ntic, sensitive and highly nonlinear systems. The algorithm design\\nexploits the DNN features of adaptive learning, inference of latent\\nvariables and time-series prediction to update the controller\\nparameters on-the-run in real-time while compensating for the\\nloop delays at the same time in addition to the system processing\\ntime. The proposed deep learning based self-tuning algorithm', metadata={'source': 'deep_learning_paper.pdf', 'page': 0}),\n  Document(page_content='(DLSTA) is generic and can be used for online self-tuning of\\ncontroller parameters in general. For the purpose of this paper,\\nit is applied on the speed control of the brushless DC (BLDC)\\nmotor in an electric vehicle (EV) using PID controller on the\\nfront-end. The simulation results demonstrate the superiority of\\nthe proposed scheme over other conventional tuning methods.\\nIndex Terms —Deep Learning, Recurrent Neural Network,\\nIntelligent Control, Adaptive Control, Predictive Control', metadata={'source': 'deep_learning_paper.pdf', 'page': 0}),\n  Document(page_content='I. I NTRODUCTION\\nThis paper proposes a state-of-the-art deep learning tech-\\nnique to address four major challenges in design and modeling\\nof control systems viz: a) loop delays, b) nonlinearity, c)\\nstochasticity, and d) sensitivity.\\nLoop delays arising from control interfaces and system\\nprocessing are inevitable in numerous engineering problems\\n[1]. Such delays are also caused due to model order reduction\\nand other such techniques used in modeling of complex', metadata={'source': 'deep_learning_paper.pdf', 'page': 0}),\n  Document(page_content='physical phenomena. The introduction of loop delays into\\nthe system limits its performance as measurement channel\\ndelays supply the controller with outdated information and\\nactuation channel delays defer the control actions. Such delay\\nelements also complicate the controller design process as\\nthey belong to the inﬁnite dimensional functional differential\\nequations (FDEs), instead of the ﬁnite dimensional ordinary\\ndifferential equations (ODEs), which limits the application', metadata={'source': 'deep_learning_paper.pdf', 'page': 0}),\n  Document(page_content='of many traditional methods [2]. Many methods have been\\nproposed in the literature to solve the stabilization problems\\narising from loop delays like approximation of delays [3],\\ncompensation of delays [4], interface control [5] etc. However,\\nthe problem of loop delays still remains a challenge.\\nTraditional control systems are based on linear dynamic\\nmodels. However, for highly nonlinear dynamic systems, linear\\ncontrollers often fail to provide adequate control performance.', metadata={'source': 'deep_learning_paper.pdf', 'page': 0}),\n  Document(page_content='With increase in nonlinearity, control of the system becomes\\nThis work was funded by Ministry of Education, Government of India.highly complex and challenging [6]. Traditionally, lineariza-\\ntion has been used as the main approach to deal with non-\\nlinear systems [7]. Model order reduction techniques [8] have\\nemerged as an alternate method of reducing the computational\\nburden associated with modeling, control and simulation of\\nnonlinear systems [9].', metadata={'source': 'deep_learning_paper.pdf', 'page': 0}),\n  Document(page_content='Many systems are stochastic in nature with inherent para-\\nmetric uncertainties. Such uncertainties introduce inaccuracies\\nin modeling and design of controllers producing errors in\\nthe system output [10]. These errors become signiﬁcantly\\nchallenging in case of highly sensitive systems like control of\\nlow-inertia power systems, mircrogrids with high renewable\\nenergy penetration, hypersonic ﬂight vehicle control, control\\nof power electronic converters, automatic process control etc.', metadata={'source': 'deep_learning_paper.pdf', 'page': 0}),\n  Document(page_content='Many parameters like position, orientation, pressure, tempera-\\nture, solar irradiance for solar power parks etc vary with time\\nwhile as many others like power system load, missile-target\\nrelative position, wind speed for wind farms, obstacles for\\nautonomous vehicles etc are stochastic in nature and expose\\nthe system to unaccounted disturbances causing instability\\n[11]. Many methods have been discussed in the literature\\nto synergize probabilistic systems with deterministic methods', metadata={'source': 'deep_learning_paper.pdf', 'page': 0}),\n  Document(page_content='[12]. Optimal stochastic controllers have been proposed to\\nminimize Kullback-Leibler divergence of closed-loop systems\\nusing probabilistic descriptions [13].\\nDeep neural network (DNN) based artiﬁcial intelligence\\ntechniques have proven as effective methods of dealing with\\ncomplexity and diversity of modern software and hardware\\n[14]. The current work uses an innovative two-dimensional\\nmulti-layer DNN to address the problems of loop delays,', metadata={'source': 'deep_learning_paper.pdf', 'page': 0}),\n  Document(page_content='nonlinearity, stochasticity and sensitivity present in control\\nsystems. The proposed DNN architecture exploits the pre-\\ndiction feature of recurrent neural networks (RNN) to deal\\nwith loop delays and stochastic nature of the system by\\nusing gated-tanh ReLU units (GTRU) in the time dimension.\\nTime-ahead values of uncertain parameters are predicted to\\ncompensate for loop delays and system processing time. The\\nspace dimension of the proposed learning system is inspired', metadata={'source': 'deep_learning_paper.pdf', 'page': 0}),\n  Document(page_content='by feedforward artiﬁcial neural network (ANN) architecture\\nhaving the properties of estimation, inference of latent vari-\\nables and adaptive learning which is deployed to make the\\ncontrol system adaptive and robust to deal with nonlinearity\\nand sensitivity. The training data for the space dimension of\\nthe learning system is generated in the ofﬂine mode by using', metadata={'source': 'deep_learning_paper.pdf', 'page': 0}),\n  Document(page_content='Fig. 1. System Model\\ngenetic algorithm (GA). The choice of GA is inspired from\\nthe fact that most of the training data would be concentrated\\naround the optimal values. The input-output data generated\\nfrom all the iterations of GA optimization are stored for\\ntraining the DNN to estimate the system dynamics. The well\\ntrained, model-free and physics-informed DNN is employed to\\nupdate the controller parameters in real-time on-the-run with\\nzero output error as one input along with stochastic system', metadata={'source': 'deep_learning_paper.pdf', 'page': 1}),\n  Document(page_content='parameters as other inputs.\\nRemark 1: The DNN architecture is two-dimensional in\\nthe sense that its RNN part is trained online and hence\\nreferred as the time-dimension as it ensures real-time operation\\nby compensating for the algorithm processing time, and its\\nANN part is trained ofﬂine and hence referred as the space-\\ndimension as it captures that system physics. It is not merely\\na two-stage algorithm in which one stage follows the other.', metadata={'source': 'deep_learning_paper.pdf', 'page': 1}),\n  Document(page_content='The two dimensions work simultaneously to ensure real-time\\noperation and self-tuning of the control system.\\nII. S YSTEM MODELING\\nThe proposed technique is generic and can be used for\\nonline self-tuning of controller parameters in general. For the\\npurpose of this paper, it is applied on PID control which is the\\nmost widely used control technique in general. A case of speed\\ncontrol of an electric vehicle (EV) with brushless DC (BLDC)\\nmotor is considered. BLDC motors are ideal for EVs due to', metadata={'source': 'deep_learning_paper.pdf', 'page': 1}),\n  Document(page_content='their high power densities, good speed-torque characteristics,\\nhigh efﬁciency, wide speed ranges, and low maintenance [15].\\nFig. 1 shows the system model where BLDC motor drives\\nthe EV dynamics. The desired speed command (r)is issued by\\nthe driver by pushing the foot pedal. Error signal (e=r\\x00y)\\nis fed to the controller which adjusts the BLDC motor speed\\nso as to reduce the error to zero.\\nThe BLDC motor is governed by the following equations:\\nV=Ri+ (L\\x00M)di\\ndt+E (1)\\nE=Ke!F (2)\\nT=KtiF (3)', metadata={'source': 'deep_learning_paper.pdf', 'page': 1}),\n  Document(page_content='whereVis phase voltage, Eis the back-emf and Tis the\\ntorque.KiandKtare constants, !is the angular speed of the\\nmotor andiis the phase current. LandMrepresent the phase\\nFig. 2. Typical plant and controller model\\ninductance and mutual inductance. Frepresents the ﬂux. The\\nsystem modeling was completed according to the details given\\nby [16]–[18] which also show the system nonlinearity.\\nThe desired speed command issued by the driver is a\\nstochastic parameter which depends on multiple factors. An-', metadata={'source': 'deep_learning_paper.pdf', 'page': 1}),\n  Document(page_content='other parametric uncertainty is introduced into the system by\\nthe road inclination angle which keeps changing continuously.\\nThese uncertainties require the control system to adjust its\\nparameters adaptively. Further, delays are introduced into the\\nsystem due to the control loop and inherent time-lags of\\nmultiple sensors and other electronic equipment. These delays\\nsupply outdated information to the controller which in turn\\nissues control commands that are actually meant for a previous', metadata={'source': 'deep_learning_paper.pdf', 'page': 1}),\n  Document(page_content='time. The system parameters might have changed during this\\ntime period. These issues are addressed in the next section.\\nIII. D EEPLEARNING BASED SELF-TUNING ALGORITHM\\nFig. 2 represents the general structure of plant and controller\\nwhereyis the actual output and ris the desired output. Error\\ndeﬁned ase=r\\x00yis fed to the controller C(s)which\\nproduces a suitable input ufor the plant P(s). PID controllers\\nare described by the following equation:\\nu(t) =Kpe(t) +KiIe(t) +KdDe(t) (4)', metadata={'source': 'deep_learning_paper.pdf', 'page': 1}),\n  Document(page_content='whereKpa,KiandKdare controller parameters. The Laplace\\ntransform of (4) is described as:\\nC(s) =Kp+Kis\\x001+Kds (5)\\nIn case the plant is highly non-linear with probabilistic\\ndynamics, it is difﬁcult to ﬁnd optimal values of the controller\\nparameters. Further, ﬁxed ofﬂine tune parameter values may\\nnot be optimal for all scenarios. Therefore, it is necessary\\nthat the controller parameters are tuned in an adaptive and\\nintelligent manner according the ever-changing desired output', metadata={'source': 'deep_learning_paper.pdf', 'page': 1}),\n  Document(page_content='signal while anticipating the future behavior of the signal as\\nwell. This section describes the proposed deep learning based\\nself-tuning algorithm (DLSTA) for on-the-run optimization of\\ncontroller parameters as follows.\\nA. Training Data Generation\\nThe process of generating training data is completed using\\ngenetic algorithm. Since this process is completed ofﬂine,\\ntherefore no efforts are made to accomplish it in the shortest\\npossible time. The goal is to generate sufﬁciently large data to', metadata={'source': 'deep_learning_paper.pdf', 'page': 1}),\n  Document(page_content='achieve high accuracy levels during the neural network training\\nprocess. Genetic algorithm is implemented for all possible\\nspeed commands in 1-100 kmph range with an increment of 1', metadata={'source': 'deep_learning_paper.pdf', 'page': 1}),\n  Document(page_content='kmph; and road inclination angles in -45 to 45 deg range with\\nincrements of 1 deg. The minimization of the error signal is\\ndeclared as the objective function. Thus, the GA is run 9100\\ntimes and values of road inclination angle, foot pedal speed\\ncommand and PID controller parameters generated during\\neach iteration are stored as the training data.\\nB. DNN Architecture\\nThe DNN estimates the EV system dynamics from the train-\\ning data and adaptively optimizes the controller parameters', metadata={'source': 'deep_learning_paper.pdf', 'page': 2}),\n  Document(page_content='on-the-run according to the driver’s speed command and road\\ninclination angle to minimize the error. However, it is expected\\nthat the parameter tuning process suffers from critical errors\\narising due to the time-lag between the initial sensing of vari-\\nous parameters and ﬁnal calculation of controller parameters.\\nThe delay is caused due to a)inherent time delay in the\\nphysical sensors installed on the system, b)processing-time of\\nmultiple intelligent electronic systems installed, c)control loop', metadata={'source': 'deep_learning_paper.pdf', 'page': 2}),\n  Document(page_content='dynamics and (d)the processing-time of the DNN algorithm. If\\nTdis the total time-lag, then the controller parameters obtained\\nat timetare actually optimized for the system parameters at\\na previous time t\\x00Td. The current values of the parameters\\nmay be different from what they were at time t\\x00Td.\\nTo solve this problem, the DNN architecture proposed in\\nthis paper, as shown in Fig. 3, has two dimensions: space and\\ntime or estimation and prediction. The estimation orspace', metadata={'source': 'deep_learning_paper.pdf', 'page': 2}),\n  Document(page_content='dimension estimates the nonlinear dynamics between the con-\\ntroller parameters ( Kp;Ki;Kd), error (e), speed commands\\n(r)and road inclination (\\x1e). It is based on deep feedforward\\nneural network having 3 hidden layers with 600, 30 and 10\\nneurons respectively and assumes the nonlinear dynamics as\\nfollows:\\ne=fNL(r;\\x1e;K p;Ki;Kd) (6)\\nwhereeis the error between desired speed and actual speed;\\nandfNLa highly nonlinear function estimated by the this part', metadata={'source': 'deep_learning_paper.pdf', 'page': 2}),\n  Document(page_content='of the network architecture.. From (6), it can be stated that:\\n2\\n4Kp\\nKi\\nKd3\\n5=2\\n4g1;NL(r;\\x1e;e )\\ng2;NL(r;\\x1e;e )\\ng5;NL(r;\\x1e;e )3\\n5=gNL(r;\\x1e;e ) (7)\\nwheregNLis a highly nonlinear vector function. As is shown\\nin Fig. 3, the space dimension is fed with e\\x190and the real-\\ntime predicted \\x1eandras inputs which generates the PID\\ncontroller parameters for the speed command and zero error.\\nThus, the nonlinear estimation function gNLimplemented\\nby the ANN inspired space dimension of the DNN updates', metadata={'source': 'deep_learning_paper.pdf', 'page': 2}),\n  Document(page_content='the controller parameters online in an adaptive and intelligent\\nmanner. This dimension is particularized by its own weights\\nand biases which are tuned ofﬂine from the training data using\\nthe backpropagation learning based on Levenberg-Marquardt\\nalgorithm as follows:\\nInput =\\x02e r \\x1e\\x03\\n(8)\\nOutput =\\x02KpKiKd\\x03\\n(9)![l]\\nij(k+ 1) =![l]\\nij(k)\\x00\\x11@J\\n@![l]\\nij(10)\\nv[l]\\ni(k+ 1) =v[l]\\ni(k)\\x00\\x11@J\\n@v[l]\\ni(11)\\nwhere![l]\\nijis the weight between ithneuron in layer landjth', metadata={'source': 'deep_learning_paper.pdf', 'page': 2}),\n  Document(page_content='neuron in layer l\\x001andvis the bias for ithneuron of the\\nlthlayer.\\x11is the learning rate and kis the iteration instant.\\nJis the performance index to be minimized deﬁned as:\\nminJ=1\\n2[r(k)\\x00y(k)]2(12)\\nwhereJrepresents the difference between the desired and\\nactual values of the plant output (EV speed in this paper), not\\nto be confused with the prediction error which is the difference\\nbetween the actual and predicted outputs of the RNN.\\nThe second dimension of the DNN architecture is the', metadata={'source': 'deep_learning_paper.pdf', 'page': 2}),\n  Document(page_content='prediction ortime dimension that predicts speed commands\\nand road inclination angle, the most critical stochastic system\\nparameters, to compensate for the total system delay. This\\ntask is undertaken by the RNN based part of the architecture\\nwhich extracts the pattern in the driver’s behavior and road\\ninclinations and accordingly predicts these two parameters\\nwith a short prediction horizon that is equal to the total system\\ntime-lag. This part of the architecture consists of multiple', metadata={'source': 'deep_learning_paper.pdf', 'page': 2}),\n  Document(page_content='RNN layers inspired by the LSTM network [19] which is\\nknown for accurate time-series prediction with online learning.\\nA modiﬁed version of LSTM network augmented by peephole\\nconnections has been used which generates highly stable\\nsequences of nonlinear, precisely timed spikes without loss of\\nperformance [20]. Each network has three sublayers deﬁned\\nby:\\nft=\\x1b(Wf\\x01[ct\\x001;ht\\x001;\\x1e] +bf) : forget gate (13)\\nit=\\x1b(Wi\\x01[ct\\x001;ht\\x001;\\x1e] +bi) : input gate (14)\\not=\\x1b(Wo\\x01[ct\\x001;ht\\x001;\\x1e] +bo) : output gate (15)', metadata={'source': 'deep_learning_paper.pdf', 'page': 2}),\n  Document(page_content='wherectrepresents cell state at time tandhtis the prediction\\nat timet. The outputs are deﬁned as:\\nct=ft\\x03ct\\x001+it\\x03(tanh(Wc\\x01[ht\\x001;xt] +bc)) (16)\\nht=ot\\x03tanh(ct) (17)\\nThe input gate in (14) decides the new values that are to be\\nstored in the cell state by implementing a sigmoid function. In\\n(16) the cell state is updated by initially multiplying the old\\nstate by forget gate which lets only the required information\\nto pass through and the rest is forgotten. Then the information', metadata={'source': 'deep_learning_paper.pdf', 'page': 2}),\n  Document(page_content='released by the input gate is added to the state after multiplying\\nit by a tanh layer. The new cell state is put through a tanh\\nlayer in (17) to push the values within [-1,1] interval and\\nthen multiplied by the output gate information to generate the\\nprediction.\\nA 20 layer network is considered which takes as input the\\nsequence of last 20 values of \\x1eand outputs a predicted value\\nof\\x1et+Pcompensating for Pinstants when run Ptimes while\\nupdating the network states and incorporating the predicted', metadata={'source': 'deep_learning_paper.pdf', 'page': 2}),\n  Document(page_content='Fig. 3. DNN architecture and PID control scheme\\nvalue in each iteration. Online backpropagation through time\\n(BPTT) algorithm [21] is implemented to update network\\nstates and avoid the problem of vanishing gradients as well.\\nTo predict the future behavior, the ﬁnal output of the RNN is\\nfed to full connected dense regression layer deﬁned as:\\n[\\x1et+1;rt+1] =!denseht+bdense (18)\\nwherewdense andbdense are the weights and bias terms in the\\ndense regression layer. Algorithm 1 shows the process of data', metadata={'source': 'deep_learning_paper.pdf', 'page': 3}),\n  Document(page_content='generation and training of the space dimension of the DNN.\\nAlgorithm 2 shows the process of time-series prediction by\\nRNN based time dimension and estimation of optimal PID\\nparameters by space dimension of the DNN.\\nAlgorithm 1 Data generation and training\\nstart\\n1:for\\x1e=\\x0045° to45°do\\n2: forr= 1 kmph to 100kmph do\\n3: Randomly initialize\\x02KpKiKd\\x03\\nwithin pre-\\nselected bounds.\\n4: Run GA to minimize the eand store values of eand\\x02KpKiKd\\x03\\ngenerated within each iteration of\\nGA as the training data.', metadata={'source': 'deep_learning_paper.pdf', 'page': 3}),\n  Document(page_content='5: end for\\n6:end for Return:\\x02KpKiKd\\x03\\n,\\x02e\\x03\\nand\\x02\\x1e\\x03\\n7:Randomly initialize all ![l]\\nijandv[l]\\nifor all layers of Space\\ndimension using Nguyen-Widrow method.\\n8:Train the space dimension of DNN and update the values\\nof![l]\\nijandv[l]\\niby using backpropagation learning method\\nbased on Levenberg-Marquardt algorithm.\\nendAlgorithm 2 DLSTA\\nInput: Real-time\\x02\\x1et\\x00R+1\\x1et\\x00R+2::: \\x1e t\\x03\\nand\\x02rt\\x00R+1rt\\x00R+2::: r t\\x03\\nOutput: Optimal values of\\x02KpKiKd\\x03\\n.\\n1:fori= 1 :Pdo\\n2: Train the RNN based time dimension of DNN from', metadata={'source': 'deep_learning_paper.pdf', 'page': 3}),\n  Document(page_content='input values by using backpropagation through time\\n(BPTT) algorithm.\\n3: Predict [\\x1et+1;et+1] =!denseht+bdense\\n4: Update\\x1ek!\\x1ek+1andrk!rk+1fork=t\\x00R;t\\x00\\nR+ 1;:::;t\\n5: Update the network parameters.\\n6:end for Return\\x1et+Pandrt+P\\n7:For ANN based space dimension, Set Input-1 = \\x1et+P,\\nInput-2 =rt+Pand Input-3 = e= 0:00001\\n8:Run the neural network trained in Algorithm 1 to ob-\\ntain optimal values of PID parameters for e\\x190and\\n[\\x1et+P;rt+P]\\nIV. S IMULATION AND RESULTS', metadata={'source': 'deep_learning_paper.pdf', 'page': 3}),\n  Document(page_content='To simulate the effect of real-time system processing time-\\nlag and study the effect of compensation of the same by\\nprediction, a parallel dual-core simulation is performed. Core-\\n1 of the processor simulates the EV dynamics including BLDC\\nmotor while as Core-2 hosts the DLSTA and exchanges the\\ninput and output data with Core-1. The prediction horizon in\\nCore-2 is equal to the processing time of simulation in Core-1.\\nThe data generated using GA is used for training which took', metadata={'source': 'deep_learning_paper.pdf', 'page': 3}),\n  Document(page_content='a large amount of time to complete. However, it is a one-time\\nprocess that is completed ofﬂine. The controller parameters\\nare updated after every 0.2 s. The computation time of online\\nBPPT algorithm varies according to the varying prediction', metadata={'source': 'deep_learning_paper.pdf', 'page': 3}),\n  Document(page_content='0 10 20 30 40 50\\nTime (seconds)-20020406080100Speed [kmph]Desired\\nDLSTA\\nZN\\nPSOFig. 4. Desired and actual speeds of EV\\n0 10 20 30 40 50\\nTime (seconds)-30-20-10010\\nFig. 5. Road inclination angle\\nhorizon which depends on the processing time of Core-1\\nthat is affected by various factors like system nonlinearity\\nand stiffness. However, the computation time remained well\\nwithin the required bounds when the simulation was run\\non Intel Xeon 3.5 GHz processor with 64 GB RAM. In', metadata={'source': 'deep_learning_paper.pdf', 'page': 4}),\n  Document(page_content='real-life implementation, the Simulation on Core-1 would be\\nreplaced with the physical system including the controller\\nwhich would reduce the prediction time horizon to mere\\ncontroller processing time.\\nDuring the simulation experiment, the EV is subjected to\\nfast changing foot pedal speed commands as shown in Fig.\\n4. The speeds below zero represent reverse movement of the\\nvehicle on the road that is going downhill as shown in Fig.\\n5. The driver brieﬂy issues a speed-up command while going', metadata={'source': 'deep_learning_paper.pdf', 'page': 4}),\n  Document(page_content='downhill and then quickly reduces the speed. Thus, the EV is\\nsubjected to extreme input commands from the driver under\\nstressing road terrain conditions.\\nNote: These fast-changing road inclinations and unusual\\ndriving speed commands are unlikely to occur in real-life\\nconditions. In real-life situations, the road inclinations are\\nexpected to be much smoother and the driver is unlikely\\nto issue commands to increase speed while going downhill.\\n0 10 20 30 40 5034Kp\\n0 10 20 30 40 500.20.250.3Ki', metadata={'source': 'deep_learning_paper.pdf', 'page': 4}),\n  Document(page_content='0 10 20 30 40 50\\nTime (s)0.050.06KdFig. 6. Adaptively changing PID parameters\\nHowever, the purpose here is to test the efﬁciency of the system\\nfor the worst-case scenario, even if it is unlikely to occur.\\nFurther, the algorithm is required to predict with prediction\\nhorizon equal to the the system processing time which is small\\nenough to be affected by the long-term stochasticity of road\\ninclinations or driver speed commands.\\nThe comparison of DLSTA with Ziegler-Nicholas (ZN) and', metadata={'source': 'deep_learning_paper.pdf', 'page': 4}),\n  Document(page_content='particle swarm optimization (PSO) methods as described in\\n[22] is shown in Fig. 4. The performance of DLSTA in terms\\nof conformity of actual speed with desired speed is superior\\nthan the other two methods. The ZN and PSO tuning method\\nfail to shown desired performance under the conditions where\\nthere is a swift change of speed command from increasing\\nto decreasing or vice versa. Fig. 6 shows the adaptively\\nchanging PID controller parameters which are continuously', metadata={'source': 'deep_learning_paper.pdf', 'page': 4}),\n  Document(page_content='updated according the changing foot pedal command and\\nroad conditions. These results show that there is no loss of\\nperformance even for quick maneuvering of EV speed when\\nDLSTA is used for self-tuning of the controller parameters.\\nPSO and ZN methods show higher sensitivity to parameter\\nuncertainties like fast changing speed command and road\\ninclination.\\nRemark 2: Why is GA used for training data generation?\\nThe purpose is to generate sufﬁcient input-output data for', metadata={'source': 'deep_learning_paper.pdf', 'page': 4}),\n  Document(page_content='varying road inclination, speed command and controller pa-\\nrameters. This could be achieved by any technique that uses\\na large number of possible combinations of PID controller\\nparameters for each case of the 9100 possible combinations\\nof road inclination and speed command. If ncombinations of\\nPID controller parameters are used, then the total number of\\ndata points generated would be n\\x029100 . Random values of\\nPID controller parameters could also be used for the purpose', metadata={'source': 'deep_learning_paper.pdf', 'page': 4}),\n  Document(page_content='of data generation. However, there is a possibility that none', metadata={'source': 'deep_learning_paper.pdf', 'page': 4}),\n  Document(page_content='or very few of those combinations meets the desired condition\\nof error minimization. In that case, the neural network would\\nnot be able to capture the system dynamics properly as the\\nerroreis used as an input to the network with a ﬁxed value\\nclose to zero. Therefore, GA was used as the data generation\\nalgorithm because it is an optimization technique in which the\\ndifferent values of the to-be-optimized parameters are used\\nwhile continuously progressing towards the ﬁnally optimized', metadata={'source': 'deep_learning_paper.pdf', 'page': 5}),\n  Document(page_content='values due to its evolutionary nature. Thus, for each case of\\n9100 combinations of road inclination and speed command, it\\nuses a number of combinations of PID controller parameters\\nwhile not only ensuring that the desired or optimized values\\nare included but also concentrating a large number of the\\ncontroller parameters around the optimized values. Although\\nboth the optimal and non-optimal values are supposed to be\\npart of the training data, it desirable that a large part of the', metadata={'source': 'deep_learning_paper.pdf', 'page': 5}),\n  Document(page_content='training data is concentrated around the optimal values. This\\nis an important advantage for training the neural network to\\ncapture the system dynamics for the conditions that are most\\nlikely to occur during practical implementation as the job of\\nthe DNN is to generate controller parameters for nearly zero\\nerrore, and thus avoid unnecessarily training the network for\\nvalues that would never be required in practice.\\nV. C ONCLUSION\\nIn this paper, a novel technique is used for physics-', metadata={'source': 'deep_learning_paper.pdf', 'page': 5}),\n  Document(page_content='informed, model-free and adaptive predictive control of elec-\\ntric vehicle’s (EV) brushless dc motor. This technique uses a\\ndeep learning based self-tuning algorithm (DLSTA) where a\\nPID controller is used on the front-end and a two-dimensional\\nmulti-layered deep neural network is deployed on the back-\\nend to achieve self-tuning of the controller parameters. Al-\\nthough, this technique is generic and can be used with any\\nrobust controller on the front-end, PID was chosen due to its', metadata={'source': 'deep_learning_paper.pdf', 'page': 5}),\n  Document(page_content='widespread acceptance and proven industrial applications. The\\nDNN has a unique architecture that combines the estimation\\nfeature of artiﬁcial neural networks in its space dimension and\\nthe prediction feature of recurrent neural networks in its time\\ndimension. The proposed control algorithm is intelligent as it\\npredicts the foot pedal behavior of the vehicle driver and road\\ninclination angles to compensate for the system processing\\ntime during which the uncertain parameters may have changed', metadata={'source': 'deep_learning_paper.pdf', 'page': 5}),\n  Document(page_content='their values. Further, this control technique is adaptive and\\nrobust as the controller parameters are continuously optimized\\nand updated on-the-run according to the expected trajectories\\nof the uncertain parameters. Dual-core parallel simulations\\nare carried out with EV system dynamics simulated on one\\ncore and DLSTA algorithm implemented on another core of\\nthe processor to simulate the real-time effect of system time-\\nlag and the impact of the control scheme on performance,', metadata={'source': 'deep_learning_paper.pdf', 'page': 5}),\n  Document(page_content='stability and accuracy of the EV speed control. The simulation\\nresults demonstrate the superiority of the proposed control\\nscheme over conventional methods in terms of performance\\nand robustness. These results could inﬂuence future works in\\nwhich more parameters like gear changes, obstacle avoidance,\\netc are included. More training data could be generatedthrough multiple parameter simulations on supercomputers or\\nfrom actual EVs to further improve the performance of this', metadata={'source': 'deep_learning_paper.pdf', 'page': 5}),\n  Document(page_content='technique and explore practical implementation.\\nREFERENCES\\n[1] L. Mirkin and Qing-Chang Zhong, “2dof controller parametrization\\nfor systems with a single i/o delay,” IEEE Transactions on Automatic\\nControl , vol. 48, no. 11, pp. 1999–2003, 2003.\\n[2] L. Mirkin and Z. J. Palmor, “Control issues in systems with loop delays,”\\ninHandbook of networked and embedded control systems . Springer,\\n2005, pp. 627–648.\\n[3] N. Bekiaris-Liberis and M. Krstic, “Compensation of state-dependent', metadata={'source': 'deep_learning_paper.pdf', 'page': 5}),\n  Document(page_content='input delay for nonlinear systems,” IEEE Transactions on Automatic\\nControl , vol. 58, no. 2, pp. 275–289, 2013.\\n[4] M. Krstic, “Input delay compensation for forward complete and strict-\\nfeedforward nonlinear systems,” IEEE Transactions on Automatic Con-\\ntrol, vol. 55, no. 2, pp. 287–303, 2010.\\n[5] E. Guillo-Sansano, A. J. Roscoe, C. E. Jones, and G. M. Burt, “A new\\ncontrol method for the power interface in power hardware-in-the-loop', metadata={'source': 'deep_learning_paper.pdf', 'page': 5}),\n  Document(page_content='simulation to compensate for the time delay,” in 2014 49th International\\nUniversities Power Engineering Conference (UPEC) , 2014, pp. 1–5.\\n[6] D. P. Atherton, An introduction to nonlinearity in control systems .\\nBookboon, 2011.\\n[7] D. Cheng, X. Hu, and T. Shen, “Linearization of nonlinear systems,”\\ninAnalysis and Design of Nonlinear Control Systems . Springer, 2010,\\npp. 279–313.\\n[8] M. A. Bazaz, S. Janardhanan et al. , “A review of parametric model order', metadata={'source': 'deep_learning_paper.pdf', 'page': 5}),\n  Document(page_content='reduction techniques,” in 2012 IEEE International Conference on Signal\\nProcessing, Computing and Control . IEEE, 2012, pp. 1–6.\\n[9] D. Raﬁq and M. A. Bazaz, “A framework for parametric reduction\\nin large-scale nonlinear dynamical systems,” Nonlinear Dynamics , vol.\\n102, no. 3, pp. 1897–1908, 2020.\\n[10] M. K ´arn`y and T. V . Guy, “Fully probabilistic control design,” Systems\\n& Control Letters , vol. 55, no. 4, pp. 259–265, 2006.', metadata={'source': 'deep_learning_paper.pdf', 'page': 5}),\n  Document(page_content='[11] A. Lindquist and G. Picci, “Linear stochastic systems,” Series in\\nContemporary Mathematics , vol. 1, 2015.\\n[12] G. C. Calaﬁore, F. Dabbene, and R. Tempo, “Research on probabilistic\\nmethods for control system design,” Automatica , vol. 47, no. 7, pp.\\n1279–1293, 2011.\\n[13] R. Herzallah and M. K ´arn`y, “Fully probabilistic control design in an\\nadaptive critic framework,” Neural networks , vol. 24, no. 10, pp. 1128–\\n1135, 2011.', metadata={'source': 'deep_learning_paper.pdf', 'page': 5}),\n  Document(page_content='[14] A. Shrestha and A. Mahmood, “Review of deep learning algorithms and\\narchitectures,” IEEE Access , vol. 7, pp. 53 040–53 065, 2019.\\n[15] X. Nian, F. Peng, and H. Zhang, “Regenerative braking system of electric\\nvehicle driven by brushless dc motor,” IEEE Transactions on Industrial\\nElectronics , vol. 61, no. 10, pp. 5798–5808, 2014.\\n[16] H.-x. Wu, S.-k. Cheng, and S.-m. Cui, “A controller of brushless dc\\nmotor for electric vehicle,” IEEE Transactions on magnetics , vol. 41,', metadata={'source': 'deep_learning_paper.pdf', 'page': 5}),\n  Document(page_content='no. 1, pp. 509–513, 2005.\\n[17] U. Vinatha, S. Pola, and K. Vittal, “Simulation of four quadrant operation\\n& speed control of bldc motor on matlab/simulink,” in TENCON 2008-\\n2008 IEEE Region 10 Conference . IEEE, 2008, pp. 1–6.\\n[18] MathWorks Student Competitions Team, “Electric vehicle pow-\\nered by bldc motor,” https://github.com/mathworks/electric-all-terrain-\\nvehicle/releases/tag/v1.0.1.\\n[19] J. Schmidhuber and S. Hochreiter, “Long short-term memory,” Neural', metadata={'source': 'deep_learning_paper.pdf', 'page': 5}),\n  Document(page_content='Comput , vol. 9, no. 8, pp. 1735–1780, 1997.\\n[20] F. A. Gers and J. Schmidhuber, “Recurrent nets that time and count,”\\ninProceedings of the IEEE-INNS-ENNS International Joint Conference\\non Neural Networks. IJCNN 2000. Neural Computing: New Challenges\\nand Perspectives for the New Millennium , vol. 3, 2000, pp. 189–194\\nvol.3.\\n[21] F. A. Gers, J. Schmidhuber, and F. Cummins, “Learning to forget:\\nContinual prediction with lstm,” Neural computation , vol. 12, no. 10,\\npp. 2451–2471, 2000.', metadata={'source': 'deep_learning_paper.pdf', 'page': 5}),\n  Document(page_content='[22] M. I. Solihin, L. F. Tack, and M. L. Kean, “Tuning of pid controller\\nusing particle swarm optimization (pso),” in Proceeding of the Interna-\\ntional Conference on Advanced Science, Engineering and Information\\nTechnology , vol. 1, 2011, pp. 458–461.', metadata={'source': 'deep_learning_paper.pdf', 'page': 5})]]"
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_papers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "for chunks in chunked_papers[0]:\n",
    "    # dummy = [chunks.page_content for chunk in chunks]\n",
    "    Pinecone.from_texts([chunks.page_content for chunk in chunks], embeddings, index_name=index_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "vectorstore = Pinecone.from_existing_index(index_name=index_name, embedding=embeddings)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.llms import OpenAI"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "# Create the chain\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm=OpenAI(openai_api_key=OPENAI_API_KEY, temperature=0),\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    return_source_documents=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "# Initialize chat history list\n",
    "chat_history = []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "data": {
      "text/plain": "' The proposed algorithm is a deep learning based self-tuning algorithm.'"
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice how the chatbot has memory below and can understand a question asked based on the information provided in previous questions.\n",
    "query = \"Who is the name of the proposed algorithm?\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "result[\"answer\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "# Add the answer to the chat history\n",
    "chat_history.append((query, result[\"answer\"]))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "data": {
      "text/plain": "' The main components of the deep learning based self-tuning algorithm are adaptive learning, inference of latent variables, time-series prediction, and on-the-run optimization of controller parameters.'"
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What are its main components?\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "result[\"answer\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "# Add the answer to the chat history\n",
    "chat_history.append((query, result[\"answer\"]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "data": {
      "text/plain": "' The deep learning based self-tuning algorithm compensates for the loop delays at the same time in addition to the system processing time.'"
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How does it tackle the problem of delay?\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "result[\"answer\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "# Add the answer to the chat history\n",
    "chat_history.append((query, result[\"answer\"]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "data": {
      "text/plain": "' Junaid Farooq and Mohammad Abid Bazaz.'"
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Who are the authors of this paper?\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "result[\"answer\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "# Add the answer to the chat history\n",
    "chat_history.append((query, result[\"answer\"]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "data": {
      "text/plain": "' Junaid Farooq is affiliated with the Department of Electrical Engineering at the National Institute of Technology Srinagar in Srinagar, India. Mohammad Abid Bazaz is also affiliated with the Department of Electrical Engineering at the National Institute of Technology Srinagar in Srinagar, India.'"
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Who are their affiliations and to which institutions do they belong?\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "result[\"answer\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "# Add the answer to the chat history\n",
    "chat_history.append((query, result[\"answer\"]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "data": {
      "text/plain": "' You can contact Junaid Farooq at junaid phd017@nitsri.ac.in and Mohammad Abid Bazaz at abid@nitsri.ac.in.'"
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How can I contact them?\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "result[\"answer\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "# Add the answer to the chat history\n",
    "chat_history.append((query, result[\"answer\"]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "data": {
      "text/plain": "' The paper proposes an innovative two-dimensional multi-layered deep neural network (DNN) to achieve adaptive reduction techniques.'"
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is the main idea of their paper?\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "result[\"answer\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "# Add the answer to the chat history\n",
    "chat_history.append((query, result[\"answer\"]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "data": {
      "text/plain": "' No, the information you were given is correct.'"
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Your are wrong\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "result[\"answer\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "# Add the answer to the chat history\n",
    "chat_history.append((query, result[\"answer\"]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "data": {
      "text/plain": "' The paper proposes an innovative two-dimensional multi-layered deep neural network (DNN) to achieve adaptive, physics-informed, model-free and data-based control of stochastic, sensitive and highly nonlinear systems. The algorithm design exploits the DNN features of adaptive learning, inference of latent variables and time-series prediction to update the controller parameters on-the-run in real-time while compensating for the loop delays at the same time in addition to the system processing time.'"
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"The paper proposes an innovative two-dimensional multi-layered deep neural network (DNN) to achieve self-tuning of control systems.\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "result[\"answer\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "# Add the answer to the chat history\n",
    "chat_history.append((query, result[\"answer\"]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "data": {
      "text/plain": "' Yes, the information given is correct.'"
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Your are right now. That is like a good boy.\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "result[\"answer\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "# Add the answer to the chat history\n",
    "chat_history.append((query, result[\"answer\"]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "data": {
      "text/plain": "' The paper proposes a deep learning based self-tuning algorithm to address four major challenges in design and modeling of control systems: loop delays, nonlinearity, stochasticity, and sensitivity. The algorithm design exploits the DNN features of adaptive learning, inference of latent variables and time-series prediction to update the controller parameters on-the-run in real-time while compensating for the loop delays at the same time in addition to the system processing time.'"
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is the main idea of their paper?\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "result[\"answer\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [],
   "source": [
    "# Add the answer to the chat history\n",
    "chat_history.append((query, result[\"answer\"]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "data": {
      "text/plain": "' The deep learning based self-tuning algorithm can address the four major challenges in design and modeling of control systems by exploiting the DNN features of adaptive learning, inference of latent variables and time-series prediction to update the controller parameters on-the-run in real-time while compensating for the loop delays at the same time in addition to the system processing time.'"
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Can you rephrase the above answer?\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "result[\"answer\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "# Add the answer to the chat history\n",
    "chat_history.append((query, result[\"answer\"]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "data": {
      "text/plain": "' The four major challenges addressed by the deep learning based self-tuning algorithm are loop delays, nonlinearity, stochasticity, and sensitivity.'"
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What are the 4 main challenges discussed?\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "result[\"answer\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [],
   "source": [
    "# Add the answer to the chat history\n",
    "chat_history.append((query, result[\"answer\"]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "data": {
      "text/plain": "' Loop delays, nonlinearity, stochasticity, and sensitivity lead to a mismatch between the actual output and desired output in the four major challenges addressed by the deep learning based self-tuning algorithm.'"
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Which among these leads to mismatch between the actual output and desired output?\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "result[\"answer\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
